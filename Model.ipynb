{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKutl_4oigXR"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/archana53/power-law-for-CI.git"
      ],
      "metadata": {
        "id": "8Jww3GQUeYX9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "baujg3n9_xzb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/power-law-for-CI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIdrivZP5caU",
        "outputId": "ba543412-2dab-43fa-c3f9-3b2328c2c359"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/power-law-for-CI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXqzSSrzbkw6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import torch\n",
        "from torch.nn import Linear, CrossEntropyLoss, Conv2d, Dropout\n",
        "from torch.nn.functional import relu, softmax, tanh\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from data_loading import permute_train_test_data\n",
        "# from pytorch_lightning import LightningModule, Trainer\n",
        "# from pytorch_lightning.callbacks.progress import TQDMProgressBar"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSFORMS = [\n",
        "        transforms.Pad(2),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        "\n",
        "dataset_tranforms = transforms.Compose(TRANSFORMS)"
      ],
      "metadata": {
        "id": "q2cYXVSI7S4t"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=dataset_tranforms)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=dataset_tranforms)"
      ],
      "metadata": {
        "id": "lZ-2fdpFadjw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_permutations , test_permutations = permute_train_test_data(mnist_trainset,mnist_testset)"
      ],
      "metadata": {
        "id": "sLWGW06g7d1W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuGG19J6QzO"
      },
      "source": [
        "# class Net1(LightningModule):\n",
        "class Net1(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net1, self).__init__()\n",
        "        #FC Layers\n",
        "        self.fc1 = Linear(input_size, hidden_size)\n",
        "        self.fc2 = Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = Linear(hidden_size, hidden_size)\n",
        "        self.fc4 = Linear(hidden_size, output_size)      \n",
        "\n",
        "        #DropOut Layers\n",
        "        self.dropout1 = Dropout(0.2)\n",
        "        self.dropout2 = Dropout(0.5)\n",
        "        self.dropout3 = Dropout(0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        data = data.view(-1, input_size)\n",
        "        data = relu(self.fc1(data))\n",
        "        data = self.dropout1(data)\n",
        "\n",
        "        data = relu(self.fc2(data))\n",
        "        data = self.dropout2(data)\n",
        "\n",
        "        data = relu(self.fc3(data))\n",
        "        data = self.dropout3(data)\n",
        "\n",
        "        data = self.fc3(data)\n",
        "        return data\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        loss = F.cross_entropy(self(x), y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=0.001)\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "gVIJLkwNoBQh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 32*32\n",
        "hidden_size = 400 \n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "fGIhGXAulTIJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for task in range(0, 10):\n",
        "  net = Net1(input_size, hidden_size, num_classes).to(device)\n",
        "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "  loss_func = CrossEntropyLoss()\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=training_permutations[task], batch_size=batch_size, shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_permutations[task], batch_size=batch_size, shuffle=False)\n",
        "  for epoch in range(num_epochs):\n",
        "      trainloss = 0.0\n",
        "      n_total_steps = len(train_loader)\n",
        "      net.train()\n",
        "      for i, (images, labels) in enumerate(train_loader):  \n",
        "          # print(images.shape)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = net(images)\n",
        "          loss = loss_func(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step() \n",
        "          #accumalting training loss for plotting\n",
        "          trainloss += loss.item()\n",
        "      train_loss.append(trainloss/n_total_steps)\n",
        "\n",
        "\n",
        "      net.eval()\n",
        "      with torch.no_grad():\n",
        "          n_correct = 0\n",
        "          n_samples = 0\n",
        "          valloss = 0.0\n",
        "          for images, labels in test_loader:\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              outputs = net(images)\n",
        "              loss = loss_func(outputs, labels)\n",
        "              valloss += loss.item()\n",
        "      val_loss.append(valloss/len(test_loader))    \n",
        "\n",
        "      if (epoch) % 5 == 0:\n",
        "              print (f'Task {task}, Epoch [{epoch+1}/{num_epochs}], Train Loss: {trainloss/n_total_steps:.4f} Validation Loss: {valloss/len(test_loader):.4f}')"
      ],
      "metadata": {
        "id": "U3y2WcSNkg5S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swSSBEzVbdJ4"
      },
      "source": [
        "# plt.figure(figsize=(10,10))\n",
        "\n",
        "# plt.subplot(2,1,1)\n",
        "# plt.plot(train_loss, label=\"Training Loss\")\n",
        "# plt.plot(val_loss, label=\"Validation Loss\")\n",
        "# plt.legend()\n",
        "\n",
        "# # plt.subplot(2,1,2)\n",
        "# # plt.plot(acc, label=\"Training Accuracy\")\n",
        "# # plt.plot(val_ac, label=\"Validation Accuracy\")\n",
        "# # plt.legend()\n",
        "\n",
        "# # plt.savefig(\"/content/drive/My Drive/\"+net.name+\".png\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist_model = Net1(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# # Init DataLoader from MNIST Dataset\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=training_permutations[0], batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_permutations[0], batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # Initialize a trainer\n",
        "# trainer = Trainer(\n",
        "#     accelerator=\"auto\",\n",
        "#     devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
        "#     max_epochs=num_epochs,\n",
        "#     callbacks=[TQDMProgressBar(refresh_rate=20), EarlyStopping(monitor='val_loss', patience=5)],\n",
        "# )\n",
        "\n",
        "# # Train the model âš¡\n",
        "# trainer.fit(mnist_model, train_loader)"
      ],
      "metadata": {
        "id": "24-7kwtb9h8t"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}