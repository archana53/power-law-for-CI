{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EWC_model import *\n",
    "from train import * \n",
    "from training_environment_setup import get_all_training_environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_six'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -conv-layers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m        depth=depth,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m        conv_type=args.conv_type if depth>0 else None,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m        global_pooling=checkattr(args, 'gp') if depth>0 else None,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# -fc-layers\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfc_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfc_drop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfc_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfc_bn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/EWC_model.py:246\u001b[0m, in \u001b[0;36mClassifier.__init__\u001b[0;34m(self, image_size, image_channels, classes, conv_type, depth, start_channels, reducing_layers, conv_bn, conv_nl, num_blocks, global_pooling, no_fnl, conv_gated, fc_layers, fc_units, fc_drop, fc_bn, fc_nl, fc_gated, bias, excitability, excit_buffer, phantom)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_out_channels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvE\u001b[39m.\u001b[39mout_channels\n\u001b[1;32m    244\u001b[0m \u001b[39m#------------------------------------------------------------------------------------------#\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m#--> fully connected hidden layers\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfcE \u001b[39m=\u001b[39m MLP(input_size\u001b[39m=\u001b[39;49mimage_size ,output_size\u001b[39m=\u001b[39;49mfc_units, layers\u001b[39m=\u001b[39;49mfc_layers\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    247\u001b[0m                hid_size\u001b[39m=\u001b[39;49mfc_units, drop\u001b[39m=\u001b[39;49mfc_drop, batch_norm\u001b[39m=\u001b[39;49mfc_bn, nl\u001b[39m=\u001b[39;49mfc_nl, bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m    248\u001b[0m                excitability\u001b[39m=\u001b[39;49mexcitability, excit_buffer\u001b[39m=\u001b[39;49mexcit_buffer, gated\u001b[39m=\u001b[39;49mfc_gated, phantom\u001b[39m=\u001b[39;49mphantom)\n\u001b[1;32m    249\u001b[0m mlp_output_size \u001b[39m=\u001b[39m fc_units \u001b[39mif\u001b[39;00m fc_layers\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_out_units\n\u001b[1;32m    250\u001b[0m \u001b[39m#--> classifier\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/models/fc/nets.py:70\u001b[0m, in \u001b[0;36mMLP.__init__\u001b[0;34m(self, input_size, output_size, layers, hid_size, hid_smooth, size_per_layer, drop, batch_norm, nl, bias, excitability, excit_buffer, gated, phantom, output)\u001b[0m\n\u001b[1;32m     68\u001b[0m     out_size \u001b[39m=\u001b[39m size_per_layer[lay_id]\n\u001b[1;32m     69\u001b[0m     \u001b[39m# define and set the fully connected layer\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     layer \u001b[39m=\u001b[39m fc_layer(\n\u001b[1;32m     71\u001b[0m         in_size, out_size, bias\u001b[39m=\u001b[39;49mbias, excitability\u001b[39m=\u001b[39;49mexcitability, excit_buffer\u001b[39m=\u001b[39;49mexcit_buffer,\n\u001b[1;32m     72\u001b[0m         batch_norm\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m (lay_id\u001b[39m==\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m output\u001b[39m==\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnormal\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39melse\u001b[39;49;00m batch_norm, gated\u001b[39m=\u001b[39;49mgated,\n\u001b[1;32m     73\u001b[0m         nl\u001b[39m=\u001b[39;49mnl, drop\u001b[39m=\u001b[39;49mdrop \u001b[39mif\u001b[39;49;00m lay_id\u001b[39m>\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m0.\u001b[39;49m, phantom\u001b[39m=\u001b[39;49mphantom\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     75\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfcLayer\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(lay_id), layer)\n\u001b[1;32m     77\u001b[0m \u001b[39m# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/models/fc/layers.py:20\u001b[0m, in \u001b[0;36mfc_layer.__init__\u001b[0;34m(self, in_size, out_size, nl, drop, bias, batch_norm, excitability, excit_buffer, gated, phantom)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m drop\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(drop)\n\u001b[0;32m---> 20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m em\u001b[39m.\u001b[39;49mLinearExcitability(in_size, out_size, bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m batch_norm \u001b[39melse\u001b[39;49;00m bias,\n\u001b[1;32m     21\u001b[0m                                     excitability\u001b[39m=\u001b[39;49mexcitability, excit_buffer\u001b[39m=\u001b[39;49mexcit_buffer)\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m batch_norm:\n\u001b[1;32m     23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBatchNorm1d(out_size)\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/models/fc/excitability_modules.py:51\u001b[0m, in \u001b[0;36mLinearExcitability.__init__\u001b[0;34m(self, in_features, out_features, bias, excitability, excit_buffer)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mTensor(out_features, in_features))\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m excitability:\n\u001b[1;32m     53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexcitability \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mTensor(out_features))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1283\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1281\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcannot assign parameters before Module.__init__() call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1282\u001b[0m     remove_from(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_non_persistent_buffers_set)\n\u001b[0;32m-> 1283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregister_parameter(name, value)\n\u001b[1;32m   1284\u001b[0m \u001b[39melif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   1285\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:406\u001b[0m, in \u001b[0;36mModule.register_parameter\u001b[0;34m(self, name, param)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    404\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcannot assign parameter before Module.__init__() call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 406\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(name, torch\u001b[39m.\u001b[39;49m_six\u001b[39m.\u001b[39mstring_classes):\n\u001b[1;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mparameter name should be a string. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(name)))\n\u001b[1;32m    409\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m name:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '_six'"
     ]
    }
   ],
   "source": [
    "# -conv-layers\n",
    "'''\n",
    "        depth=depth,\n",
    "        conv_type=args.conv_type if depth>0 else None,\n",
    "        start_channels=args.channels if depth>0 else None,\n",
    "        reducing_layers=args.rl if depth>0 else None,\n",
    "        num_blocks=args.n_blocks if depth>0 else None,\n",
    "        conv_bn=(True if args.conv_bn==\"yes\" else False) if depth>0 else None,\n",
    "        conv_nl=args.conv_nl if depth>0 else None,\n",
    "        no_fnl=True if depth>0 else None,\n",
    "        global_pooling=checkattr(args, 'gp') if depth>0 else None,\n",
    "'''\n",
    "model = Classifier(\n",
    "        image_size=32*32,\n",
    "        image_channels=1,\n",
    "        classes=10,\n",
    "        # -fc-layers\n",
    "        fc_units=1000,\n",
    "        fc_drop=0.2,\n",
    "        fc_layers = 4,\n",
    "        fc_bn=True\n",
    "\n",
    "    )\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.importance_weighting=='fisher'\n",
    "model.precondition = True\n",
    "model.fisher_n = None\n",
    "model.fisher_labels = 'all'\n",
    "model.fisher_batch = 1\n",
    "# -options relating to 'Offline EWC' (Kirkpatrick et al., 2017) and 'Online EWC' (Schwarz et al., 2018)\n",
    "model.offline = True\n",
    "model.weight_penalty = False\n",
    "model.reg_strength = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else :\n",
    "    device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "context:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.8421672952586207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.973700161637931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.9928609913793103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  300  : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  400  : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 500/500 [01:58<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher estimation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Estimation: 100%|██████████| 1000/1000 [00:40<00:00, 24.69it/s]\n",
      "context:  10%|█         | 1/10 [02:38<23:48, 158.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.10661368534482758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.7211745689655172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.7896012931034483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  300  : 0.8485991379310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  400  : 0.8950363685344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 500/500 [02:08<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher estimation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Estimation: 100%|██████████| 1000/1000 [00:44<00:00, 22.64it/s]\n",
      "context:  20%|██        | 2/10 [05:31<22:15, 166.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.13729121767241378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.6910695043103449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.7593952047413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  300  : 0.8217605064655172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  400  : 0.8589709051724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher estimation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Estimation: 100%|██████████| 1000/1000 [00:40<00:00, 24.72it/s]\n",
      "context:  30%|███       | 3/10 [08:37<20:30, 175.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.12186826508620689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.5608836206896551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.7000606142241379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  300  : 0.7516500538793103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  400  : 0.7405037715517242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 500/500 [02:34<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher estimation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Estimation: 100%|██████████| 1000/1000 [00:40<00:00, 24.59it/s]\n",
      "context:  40%|████      | 4/10 [11:52<18:19, 183.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.1388739224137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.5055899784482758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.6157394935344828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  300  : 0.6702249461206897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  400  : 0.7274043642241379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations: 100%|██████████| 500/500 [02:44<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fisher estimation start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Estimation: 100%|██████████| 1000/1000 [00:40<00:00, 24.85it/s]\n",
      "context:  50%|█████     | 5/10 [15:17<15:54, 190.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  0  : 0.15712553879310345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  100  : 0.4756869612068966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for iteration  200  : 0.5791352370689655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterations:  54%|█████▎    | 268/500 [01:35<01:22,  2.81it/s]\n",
      "context:  50%|█████     | 5/10 [16:52<16:52, 202.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_cl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_permutations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/train.py:71\u001b[0m, in \u001b[0;36mtrain_cl\u001b[0;34m(model, train_datasets, iters, batch_size, baseline, loss_cbs, eval_cbs, sample_cbs, context_cbs, generator, gen_iters, gen_loss_cbs, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     train_dataset \u001b[39m=\u001b[39m ConcatDataset(train_datasets[:context])\n\u001b[1;32m     68\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     69\u001b[0m train_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 71\u001b[0m train(model, dataloader, iters, loss_cbs \u001b[39m=\u001b[39;49m loss_cbs, eval_cbs\u001b[39m=\u001b[39;49meval_cbs)\n\u001b[1;32m     72\u001b[0m \u001b[39m##----------> UPON FINISHING EACH CONTEXT...\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[39m# Parameter regularization: update and compute the parameter importance estimates\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m<\u001b[39m\u001b[39mlen\u001b[39m(train_datasets) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model, EWCModel):\n\u001b[1;32m     76\u001b[0m     \u001b[39m# -find allowed classes\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/train.py:29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, iters, loss_cbs, eval_cbs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     27\u001b[0m     \u001b[39m# Perform training-step on this batch\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     data, y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m     loss_dict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_a_batch(data, y\u001b[39m=\u001b[39;49my)\n\u001b[1;32m     30\u001b[0m     y_hat \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     31\u001b[0m     acc\u001b[39m.\u001b[39mappend((y \u001b[39m==\u001b[39m y_hat\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m data\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/EWC_model.py:359\u001b[0m, in \u001b[0;36mtrain_a_batch\u001b[0;34m(self, x, y, scores, x_, y_, scores_, rnt, active_classes, context, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m             weight_penalty_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mewc_loss()\n\u001b[0;32m--> 359\u001b[0m     loss_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreg_strength \u001b[39m*\u001b[39m weight_penalty_loss\n\u001b[1;32m    362\u001b[0m \u001b[39m##--(4)-- COMPUTE (AND MANIPULATE) GRADIENTS --##\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[39m# Backpropagate errors (for the part of the loss that has not yet been backpropagated)\u001b[39;00m\n\u001b[1;32m    365\u001b[0m loss_total\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/Academics/Fall 22/HML/Course Project/power-law-for-CI/EWC_model.py:192\u001b[0m, in \u001b[0;36mEWCModel.ewc_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m context \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_penalty_terms\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    191\u001b[0m     \u001b[39mfor\u001b[39;00m gen_params \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_list:\n\u001b[0;32m--> 192\u001b[0m         \u001b[39mfor\u001b[39;00m n, p \u001b[39min\u001b[39;00m gen_params():\n\u001b[1;32m    193\u001b[0m             \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    194\u001b[0m                 \u001b[39m# Retrieve stored mode (MAP estimate) and precision (Fisher Information matrix)\u001b[39;00m\n\u001b[1;32m    195\u001b[0m                 n \u001b[39m=\u001b[39m n\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1733\u001b[0m, in \u001b[0;36mModule.named_parameters\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns an iterator over module parameters, yielding both the\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39mname of the parameter as well as the parameter itself.\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \n\u001b[1;32m   1729\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1730\u001b[0m gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_named_members(\n\u001b[1;32m   1731\u001b[0m     \u001b[39mlambda\u001b[39;00m module: module\u001b[39m.\u001b[39m_parameters\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1732\u001b[0m     prefix\u001b[39m=\u001b[39mprefix, recurse\u001b[39m=\u001b[39mrecurse)\n\u001b[0;32m-> 1733\u001b[0m \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m gen:\n\u001b[1;32m   1734\u001b[0m     \u001b[39myield\u001b[39;00m elem\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule._named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m   1673\u001b[0m memo \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   1674\u001b[0m modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_modules(prefix\u001b[39m=\u001b[39mprefix) \u001b[39mif\u001b[39;00m recurse \u001b[39melse\u001b[39;00m [(prefix, \u001b[39mself\u001b[39m)]\n\u001b[0;32m-> 1675\u001b[0m \u001b[39mfor\u001b[39;00m module_prefix, module \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1676\u001b[0m     members \u001b[39m=\u001b[39m get_members_fn(module)\n\u001b[1;32m   1677\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m members:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1885\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m submodule_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m prefix \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m name\n\u001b[0;32m-> 1885\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39mnamed_modules(memo, submodule_prefix, remove_duplicate):\n\u001b[1;32m   1886\u001b[0m     \u001b[39myield\u001b[39;00m m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1885\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m submodule_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m prefix \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m name\n\u001b[0;32m-> 1885\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39mnamed_modules(memo, submodule_prefix, remove_duplicate):\n\u001b[1;32m   1886\u001b[0m     \u001b[39myield\u001b[39;00m m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hml_project/lib/python3.10/site-packages/torch/nn/modules/module.py:1885\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m submodule_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m prefix \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m name\n\u001b[0;32m-> 1885\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39;49mnamed_modules(memo, submodule_prefix, remove_duplicate):\n\u001b[1;32m   1886\u001b[0m     \u001b[39myield\u001b[39;00m m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_lb, train_powerlaw, train_ub , test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, test_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtqdm\u001b[49m(test_permutations)):\n\u001b[1;32m      2\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_set,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     acc \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "for i, test_set in enumerate(tqdm(test_permutations)):\n",
    "    test_loader = DataLoader(test_set,batch_size=256, shuffle=True)\n",
    "    acc = []\n",
    "    for batch_idx, (data, y) in enumerate(tqdm(test_loader)):\n",
    "            # Perform training-step on this batch\n",
    "            y_hat = model(data)\n",
    "            acc.append((y == y_hat.max(1)[1]).sum().item() / data.size(0))\n",
    "    print(\"Accuracy for context \", i , \"is : \", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_DATA_SIZE = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6_/w6mgwpfd12z46rvjfl18xd400000gn/T/ipykernel_16057/842474794.py:4: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  tensor_arr = np.array(list(training_permutations[0]))[:,0]\n",
      "/var/folders/6_/w6mgwpfd12z46rvjfl18xd400000gn/T/ipykernel_16057/842474794.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor_arr = np.array(list(training_permutations[0]))[:,0]\n",
      "/var/folders/6_/w6mgwpfd12z46rvjfl18xd400000gn/T/ipykernel_16057/842474794.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  perm_x_train = np.vstack((perm_x_train, np.array(list(training_permutations[task]))[idx,0].numpy()))\n",
      "/var/folders/6_/w6mgwpfd12z46rvjfl18xd400000gn/T/ipykernel_16057/842474794.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  perm_x_train = np.vstack((perm_x_train, np.array(list(training_permutations[task]))[idx,0].numpy()))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1000 is out of bounds for axis 0 with size 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# perm_y_train = np.array(list(training_permutations[0]))[:,1]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(OVERALL_DATA_SIZE):\n\u001b[0;32m----> 7\u001b[0m   perm_x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((perm_x_train, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_permutations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;66;03m# perm_x_train = np.vstack((perm_x_train, tensor_arr[idx].numpy()))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m   perm_y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((perm_y_train, training_permutations[task][idx][\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "for task in range(10):\n",
    "  perm_x_train = np.empty((0,32,32))\n",
    "  perm_y_train = np.empty((0,))\n",
    "  tensor_arr = np.array(list(training_permutations[0]))[:,0]\n",
    "  # perm_y_train = np.array(list(training_permutations[0]))[:,1]\n",
    "  for idx in range(OVERALL_DATA_SIZE):\n",
    "    perm_x_train = np.vstack((perm_x_train, np.array(list(training_permutations[task]))[idx,0].numpy()))\n",
    "    # perm_x_train = np.vstack((perm_x_train, tensor_arr[idx].numpy()))\n",
    "    perm_y_train = np.hstack((perm_y_train, training_permutations[task][idx][1]))\n",
    "  np.save('permuted_dataset_task_' + str(task) + '_X.npy', perm_x_train, allow_pickle=True)\n",
    "  np.save('permuted_dataset_task_' + str(task) + '_Y.npy', perm_y_train, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('hml_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c06359541bab7741f5b8a7a51e0e45335cfb5c188357344206c64fc8f256a6c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
